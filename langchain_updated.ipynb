{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "257e16ee-901a-485e-90cb-1961d10c7bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ec54911-d7da-4df9-91b2-1ca0acfdee4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mykey=\"your_api_key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd9f6cf1-04fd-4568-8528-1c73eb4a1634",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key=mykey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fce4aa95-2c31-48c3-b3f0-b35cff74d90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models=openai.models.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afbbab78-5aab-40df-8d8e-4ffe75cc38b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model(id='text-embedding-ada-002', created=1671217299, object='model', owned_by='openai-internal'),\n",
       " Model(id='whisper-1', created=1677532384, object='model', owned_by='openai-internal'),\n",
       " Model(id='gpt-3.5-turbo', created=1677610602, object='model', owned_by='openai'),\n",
       " Model(id='tts-1', created=1681940951, object='model', owned_by='openai-internal'),\n",
       " Model(id='gpt-3.5-turbo-16k', created=1683758102, object='model', owned_by='openai-internal'),\n",
       " Model(id='davinci-002', created=1692634301, object='model', owned_by='system'),\n",
       " Model(id='babbage-002', created=1692634615, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo-instruct', created=1692901427, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo-instruct-0914', created=1694122472, object='model', owned_by='system'),\n",
       " Model(id='dall-e-3', created=1698785189, object='model', owned_by='system'),\n",
       " Model(id='dall-e-2', created=1698798177, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo-1106', created=1698959748, object='model', owned_by='system'),\n",
       " Model(id='tts-1-hd', created=1699046015, object='model', owned_by='system'),\n",
       " Model(id='tts-1-1106', created=1699053241, object='model', owned_by='system'),\n",
       " Model(id='tts-1-hd-1106', created=1699053533, object='model', owned_by='system'),\n",
       " Model(id='text-embedding-3-small', created=1705948997, object='model', owned_by='system'),\n",
       " Model(id='text-embedding-3-large', created=1705953180, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo-0125', created=1706048358, object='model', owned_by='system'),\n",
       " Model(id='gpt-4o', created=1715367049, object='model', owned_by='system'),\n",
       " Model(id='gpt-4o-2024-05-13', created=1715368132, object='model', owned_by='system'),\n",
       " Model(id='gpt-4o-mini-2024-07-18', created=1721172717, object='model', owned_by='system'),\n",
       " Model(id='gpt-4o-mini', created=1721172741, object='model', owned_by='system'),\n",
       " Model(id='gpt-4o-2024-08-06', created=1722814719, object='model', owned_by='system'),\n",
       " Model(id='o1-mini-2024-09-12', created=1725648979, object='model', owned_by='system'),\n",
       " Model(id='o1-mini', created=1725649008, object='model', owned_by='system'),\n",
       " Model(id='gpt-4o-audio-preview-2024-10-01', created=1727389042, object='model', owned_by='system'),\n",
       " Model(id='gpt-4o-audio-preview', created=1727460443, object='model', owned_by='system'),\n",
       " Model(id='omni-moderation-latest', created=1731689265, object='model', owned_by='system'),\n",
       " Model(id='omni-moderation-2024-09-26', created=1732734466, object='model', owned_by='system'),\n",
       " Model(id='gpt-4o-audio-preview-2024-12-17', created=1734034239, object='model', owned_by='system'),\n",
       " Model(id='gpt-4o-mini-audio-preview-2024-12-17', created=1734115920, object='model', owned_by='system'),\n",
       " Model(id='gpt-4o-mini-audio-preview', created=1734387424, object='model', owned_by='system'),\n",
       " Model(id='gpt-4o-2024-11-20', created=1739331543, object='model', owned_by='system'),\n",
       " Model(id='gpt-4o-search-preview-2025-03-11', created=1741388170, object='model', owned_by='system'),\n",
       " Model(id='gpt-4o-search-preview', created=1741388720, object='model', owned_by='system'),\n",
       " Model(id='gpt-4o-mini-search-preview-2025-03-11', created=1741390858, object='model', owned_by='system'),\n",
       " Model(id='gpt-4o-mini-search-preview', created=1741391161, object='model', owned_by='system'),\n",
       " Model(id='gpt-4o-transcribe', created=1742068463, object='model', owned_by='system'),\n",
       " Model(id='gpt-4o-mini-transcribe', created=1742068596, object='model', owned_by='system'),\n",
       " Model(id='gpt-4o-mini-tts', created=1742403959, object='model', owned_by='system'),\n",
       " Model(id='gpt-4.1-2025-04-14', created=1744315746, object='model', owned_by='system'),\n",
       " Model(id='gpt-4.1', created=1744316542, object='model', owned_by='system'),\n",
       " Model(id='gpt-4.1-mini-2025-04-14', created=1744317547, object='model', owned_by='system'),\n",
       " Model(id='gpt-4.1-mini', created=1744318173, object='model', owned_by='system'),\n",
       " Model(id='gpt-4.1-nano-2025-04-14', created=1744321025, object='model', owned_by='system'),\n",
       " Model(id='gpt-4.1-nano', created=1744321707, object='model', owned_by='system'),\n",
       " Model(id='gpt-image-1', created=1745517030, object='model', owned_by='system'),\n",
       " Model(id='gpt-4o-audio-preview-2025-06-03', created=1748908498, object='model', owned_by='system')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(all_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9a2b007-bbb1-4dc0-a104-05aa671a6e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created</th>\n",
       "      <th>object</th>\n",
       "      <th>owned_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(id, text-embedding-ada-002)</td>\n",
       "      <td>(created, 1671217299)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai-internal)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(id, whisper-1)</td>\n",
       "      <td>(created, 1677532384)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai-internal)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(id, gpt-3.5-turbo)</td>\n",
       "      <td>(created, 1677610602)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(id, tts-1)</td>\n",
       "      <td>(created, 1681940951)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai-internal)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(id, gpt-3.5-turbo-16k)</td>\n",
       "      <td>(created, 1683758102)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai-internal)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(id, davinci-002)</td>\n",
       "      <td>(created, 1692634301)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(id, babbage-002)</td>\n",
       "      <td>(created, 1692634615)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(id, gpt-3.5-turbo-instruct)</td>\n",
       "      <td>(created, 1692901427)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(id, gpt-3.5-turbo-instruct-0914)</td>\n",
       "      <td>(created, 1694122472)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(id, dall-e-3)</td>\n",
       "      <td>(created, 1698785189)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(id, dall-e-2)</td>\n",
       "      <td>(created, 1698798177)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(id, gpt-3.5-turbo-1106)</td>\n",
       "      <td>(created, 1698959748)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(id, tts-1-hd)</td>\n",
       "      <td>(created, 1699046015)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(id, tts-1-1106)</td>\n",
       "      <td>(created, 1699053241)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(id, tts-1-hd-1106)</td>\n",
       "      <td>(created, 1699053533)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(id, text-embedding-3-small)</td>\n",
       "      <td>(created, 1705948997)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(id, text-embedding-3-large)</td>\n",
       "      <td>(created, 1705953180)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(id, gpt-3.5-turbo-0125)</td>\n",
       "      <td>(created, 1706048358)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(id, gpt-4o)</td>\n",
       "      <td>(created, 1715367049)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(id, gpt-4o-2024-05-13)</td>\n",
       "      <td>(created, 1715368132)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(id, gpt-4o-mini-2024-07-18)</td>\n",
       "      <td>(created, 1721172717)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(id, gpt-4o-mini)</td>\n",
       "      <td>(created, 1721172741)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(id, gpt-4o-2024-08-06)</td>\n",
       "      <td>(created, 1722814719)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(id, o1-mini-2024-09-12)</td>\n",
       "      <td>(created, 1725648979)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(id, o1-mini)</td>\n",
       "      <td>(created, 1725649008)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(id, gpt-4o-audio-preview-2024-10-01)</td>\n",
       "      <td>(created, 1727389042)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(id, gpt-4o-audio-preview)</td>\n",
       "      <td>(created, 1727460443)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(id, omni-moderation-latest)</td>\n",
       "      <td>(created, 1731689265)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(id, omni-moderation-2024-09-26)</td>\n",
       "      <td>(created, 1732734466)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(id, gpt-4o-audio-preview-2024-12-17)</td>\n",
       "      <td>(created, 1734034239)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>(id, gpt-4o-mini-audio-preview-2024-12-17)</td>\n",
       "      <td>(created, 1734115920)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>(id, gpt-4o-mini-audio-preview)</td>\n",
       "      <td>(created, 1734387424)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>(id, gpt-4o-2024-11-20)</td>\n",
       "      <td>(created, 1739331543)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>(id, gpt-4o-search-preview-2025-03-11)</td>\n",
       "      <td>(created, 1741388170)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>(id, gpt-4o-search-preview)</td>\n",
       "      <td>(created, 1741388720)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>(id, gpt-4o-mini-search-preview-2025-03-11)</td>\n",
       "      <td>(created, 1741390858)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>(id, gpt-4o-mini-search-preview)</td>\n",
       "      <td>(created, 1741391161)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>(id, gpt-4o-transcribe)</td>\n",
       "      <td>(created, 1742068463)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>(id, gpt-4o-mini-transcribe)</td>\n",
       "      <td>(created, 1742068596)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>(id, gpt-4o-mini-tts)</td>\n",
       "      <td>(created, 1742403959)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>(id, gpt-4.1-2025-04-14)</td>\n",
       "      <td>(created, 1744315746)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>(id, gpt-4.1)</td>\n",
       "      <td>(created, 1744316542)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>(id, gpt-4.1-mini-2025-04-14)</td>\n",
       "      <td>(created, 1744317547)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>(id, gpt-4.1-mini)</td>\n",
       "      <td>(created, 1744318173)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>(id, gpt-4.1-nano-2025-04-14)</td>\n",
       "      <td>(created, 1744321025)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>(id, gpt-4.1-nano)</td>\n",
       "      <td>(created, 1744321707)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>(id, gpt-image-1)</td>\n",
       "      <td>(created, 1745517030)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>(id, gpt-4o-audio-preview-2025-06-03)</td>\n",
       "      <td>(created, 1748908498)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             id                created  \\\n",
       "0                  (id, text-embedding-ada-002)  (created, 1671217299)   \n",
       "1                               (id, whisper-1)  (created, 1677532384)   \n",
       "2                           (id, gpt-3.5-turbo)  (created, 1677610602)   \n",
       "3                                   (id, tts-1)  (created, 1681940951)   \n",
       "4                       (id, gpt-3.5-turbo-16k)  (created, 1683758102)   \n",
       "5                             (id, davinci-002)  (created, 1692634301)   \n",
       "6                             (id, babbage-002)  (created, 1692634615)   \n",
       "7                  (id, gpt-3.5-turbo-instruct)  (created, 1692901427)   \n",
       "8             (id, gpt-3.5-turbo-instruct-0914)  (created, 1694122472)   \n",
       "9                                (id, dall-e-3)  (created, 1698785189)   \n",
       "10                               (id, dall-e-2)  (created, 1698798177)   \n",
       "11                     (id, gpt-3.5-turbo-1106)  (created, 1698959748)   \n",
       "12                               (id, tts-1-hd)  (created, 1699046015)   \n",
       "13                             (id, tts-1-1106)  (created, 1699053241)   \n",
       "14                          (id, tts-1-hd-1106)  (created, 1699053533)   \n",
       "15                 (id, text-embedding-3-small)  (created, 1705948997)   \n",
       "16                 (id, text-embedding-3-large)  (created, 1705953180)   \n",
       "17                     (id, gpt-3.5-turbo-0125)  (created, 1706048358)   \n",
       "18                                 (id, gpt-4o)  (created, 1715367049)   \n",
       "19                      (id, gpt-4o-2024-05-13)  (created, 1715368132)   \n",
       "20                 (id, gpt-4o-mini-2024-07-18)  (created, 1721172717)   \n",
       "21                            (id, gpt-4o-mini)  (created, 1721172741)   \n",
       "22                      (id, gpt-4o-2024-08-06)  (created, 1722814719)   \n",
       "23                     (id, o1-mini-2024-09-12)  (created, 1725648979)   \n",
       "24                                (id, o1-mini)  (created, 1725649008)   \n",
       "25        (id, gpt-4o-audio-preview-2024-10-01)  (created, 1727389042)   \n",
       "26                   (id, gpt-4o-audio-preview)  (created, 1727460443)   \n",
       "27                 (id, omni-moderation-latest)  (created, 1731689265)   \n",
       "28             (id, omni-moderation-2024-09-26)  (created, 1732734466)   \n",
       "29        (id, gpt-4o-audio-preview-2024-12-17)  (created, 1734034239)   \n",
       "30   (id, gpt-4o-mini-audio-preview-2024-12-17)  (created, 1734115920)   \n",
       "31              (id, gpt-4o-mini-audio-preview)  (created, 1734387424)   \n",
       "32                      (id, gpt-4o-2024-11-20)  (created, 1739331543)   \n",
       "33       (id, gpt-4o-search-preview-2025-03-11)  (created, 1741388170)   \n",
       "34                  (id, gpt-4o-search-preview)  (created, 1741388720)   \n",
       "35  (id, gpt-4o-mini-search-preview-2025-03-11)  (created, 1741390858)   \n",
       "36             (id, gpt-4o-mini-search-preview)  (created, 1741391161)   \n",
       "37                      (id, gpt-4o-transcribe)  (created, 1742068463)   \n",
       "38                 (id, gpt-4o-mini-transcribe)  (created, 1742068596)   \n",
       "39                        (id, gpt-4o-mini-tts)  (created, 1742403959)   \n",
       "40                     (id, gpt-4.1-2025-04-14)  (created, 1744315746)   \n",
       "41                                (id, gpt-4.1)  (created, 1744316542)   \n",
       "42                (id, gpt-4.1-mini-2025-04-14)  (created, 1744317547)   \n",
       "43                           (id, gpt-4.1-mini)  (created, 1744318173)   \n",
       "44                (id, gpt-4.1-nano-2025-04-14)  (created, 1744321025)   \n",
       "45                           (id, gpt-4.1-nano)  (created, 1744321707)   \n",
       "46                            (id, gpt-image-1)  (created, 1745517030)   \n",
       "47        (id, gpt-4o-audio-preview-2025-06-03)  (created, 1748908498)   \n",
       "\n",
       "             object                     owned_by  \n",
       "0   (object, model)  (owned_by, openai-internal)  \n",
       "1   (object, model)  (owned_by, openai-internal)  \n",
       "2   (object, model)           (owned_by, openai)  \n",
       "3   (object, model)  (owned_by, openai-internal)  \n",
       "4   (object, model)  (owned_by, openai-internal)  \n",
       "5   (object, model)           (owned_by, system)  \n",
       "6   (object, model)           (owned_by, system)  \n",
       "7   (object, model)           (owned_by, system)  \n",
       "8   (object, model)           (owned_by, system)  \n",
       "9   (object, model)           (owned_by, system)  \n",
       "10  (object, model)           (owned_by, system)  \n",
       "11  (object, model)           (owned_by, system)  \n",
       "12  (object, model)           (owned_by, system)  \n",
       "13  (object, model)           (owned_by, system)  \n",
       "14  (object, model)           (owned_by, system)  \n",
       "15  (object, model)           (owned_by, system)  \n",
       "16  (object, model)           (owned_by, system)  \n",
       "17  (object, model)           (owned_by, system)  \n",
       "18  (object, model)           (owned_by, system)  \n",
       "19  (object, model)           (owned_by, system)  \n",
       "20  (object, model)           (owned_by, system)  \n",
       "21  (object, model)           (owned_by, system)  \n",
       "22  (object, model)           (owned_by, system)  \n",
       "23  (object, model)           (owned_by, system)  \n",
       "24  (object, model)           (owned_by, system)  \n",
       "25  (object, model)           (owned_by, system)  \n",
       "26  (object, model)           (owned_by, system)  \n",
       "27  (object, model)           (owned_by, system)  \n",
       "28  (object, model)           (owned_by, system)  \n",
       "29  (object, model)           (owned_by, system)  \n",
       "30  (object, model)           (owned_by, system)  \n",
       "31  (object, model)           (owned_by, system)  \n",
       "32  (object, model)           (owned_by, system)  \n",
       "33  (object, model)           (owned_by, system)  \n",
       "34  (object, model)           (owned_by, system)  \n",
       "35  (object, model)           (owned_by, system)  \n",
       "36  (object, model)           (owned_by, system)  \n",
       "37  (object, model)           (owned_by, system)  \n",
       "38  (object, model)           (owned_by, system)  \n",
       "39  (object, model)           (owned_by, system)  \n",
       "40  (object, model)           (owned_by, system)  \n",
       "41  (object, model)           (owned_by, system)  \n",
       "42  (object, model)           (owned_by, system)  \n",
       "43  (object, model)           (owned_by, system)  \n",
       "44  (object, model)           (owned_by, system)  \n",
       "45  (object, model)           (owned_by, system)  \n",
       "46  (object, model)           (owned_by, system)  \n",
       "47  (object, model)           (owned_by, system)  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(list(all_models),columns=[\"id\",\"created\",\"object\",\"owned_by\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6db6645-e372-450f-9577-99e56e692889",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=mykey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08b32bfe-9344-45c5-a6b3-8252c5649dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=mykey)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"who won the first cricket worldcup\"}],\n",
    "    max_tokens=100,\n",
    "    n=3     #no of o/p\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1dd3dc0e-0ecd-4bed-b361-f90e019ef0dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-BysFxcbgrhMWeS4GWityUHHKXvI0n', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The first Cricket World Cup was held in 1975, and the West Indies won the tournament by defeating Australia in the final.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)), Choice(finish_reason='stop', index=1, logprobs=None, message=ChatCompletionMessage(content=\"The first Cricket World Cup was won by the West Indies team in 1975. They defeated Australia in the final match held at Lord's Cricket Ground in London.\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)), Choice(finish_reason='stop', index=2, logprobs=None, message=ChatCompletionMessage(content='The first cricket World Cup was won by the West Indies team in 1975.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1753847941, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=76, prompt_tokens=14, total_tokens=90, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56e12789-bf5b-4aa2-bbb0-f1e99592ae4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "openai.types.chat.chat_completion.ChatCompletion"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dba02356-1e3c-4af3-94be-bea9f739d825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The first Cricket World Cup was held in 1975, and the West Indies won the tournament by defeating Australia in the final.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5263099-0b2a-4b34-9262-871d4d5ecd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "002ad4d1-9f17-4697-96ee-2965090468f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_description=\"Varsha is an AI/ML enthusiast, learning happily. She loves building solutions to real-world problems. She is studying at SVCE and has secured an 8.5 CGPA.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b518d20-e3be-4968-ada3-154f9da07f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Varsha is an AI/ML enthusiast, learning happily. She loves building solutions to real-world problems. She is studying at SVCE and has secured an 8.5 CGPA.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d9a9323-010f-457e-ae8c-55024ae8e801",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple prompt to extract info from student_description in json format\n",
    "prompt=f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "grade\n",
    "college\n",
    "\n",
    "This is the body of the text to extract the information from:\n",
    "{student_description}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6c8053e-cdf2-4110-b569-84c5017a4637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPlease extract the following information from the given text and return it as a JSON object:\\n\\nname\\ngrade\\ncollege\\n\\nThis is the body of the text to extract the information from:\\nVarsha is an AI/ML enthusiast, learning happily. She loves building solutions to real-world problems. She is studying at SVCE and has secured an 8.5 CGPA.\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae23a7f1-8f64-4610-8261-2e1eb6e0630b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client=OpenAI(api_key=mykey)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34d8ec19-7d1c-49ba-8fbd-184e25486a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<openai.OpenAI at 0x29349898790>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b15a71e-e83a-428c-af60-9877461c0f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client. chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "             \"role\": \"user\",\n",
    "             \"content\": prompt\n",
    "        }\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1ae5e8c-8d32-4ac1-84b0-f253d32f41df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-BysG0JeEn8qK9BUawbjHIBC5omPxl', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"name\": \"Varsha\",\\n  \"grade\": 8.5,\\n  \"college\": \"SVCE\"\\n}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1753847944, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=27, prompt_tokens=82, total_tokens=109, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f3a9fef-93c1-4b11-b919-cb405d1f5091",
   "metadata": {},
   "outputs": [],
   "source": [
    "output=response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db00146f-84b5-4a4b-ac4d-d28599f25843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"name\": \"Varsha\",\\n  \"grade\": 8.5,\\n  \"college\": \"SVCE\"\\n}'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "37918c13-994e-44ff-ba1c-2d3fcd944ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Varsha', 'grade': 8.5, 'college': 'SVCE'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "json.loads(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "12a41534-cdf7-4c9f-9e46-d486d6db3f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic use of function calling\n",
    "student_function= [{\n",
    "    \"name\": \"extract_student_info\",\n",
    "    \"description\": \"get the student info from the body of the input text.\",\n",
    "    \"parameters\": {\n",
    "        \"type\":\"object\",\n",
    "        \"properties\":{\n",
    "            \"name\":{\n",
    "                \"type\":\"string\",\n",
    "                \"description\":\"name of the person\" },\n",
    "            \"grade\":{\n",
    "                 \"type\":\"string\",\n",
    "                \"description\":\"grade of the person\"},\n",
    "             \"college\":{\n",
    "                \"type\":\"string\",\n",
    "                \"description\":\"college of the person\"},\n",
    "    },\n",
    "     \"required\": [\"name\", \"college\", \"grade\"]\n",
    "            }}]\n",
    "            \n",
    "    \n",
    "        \n",
    "    \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7b8b3e60-5c5e-4996-bf58-aa6ed78e1abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "response2 = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    functions=student_function,\n",
    "    function_call={\"name\": \"extract_student_info\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0dd3df84-cf28-43e7-8344-615e4e973d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-BysG51CSd2c5U7YoNvshkdG2iRIbj', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=FunctionCall(arguments='{\"name\":\"Varsha\",\"grade\":\"8.5 CGPA\",\"college\":\"SVCE\"}', name='extract_student_info'), tool_calls=None))], created=1753847949, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=19, prompt_tokens=163, total_tokens=182, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8ff60933-fd5e-40a4-aead-58f926a6a402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"name\":\"Varsha\",\"grade\":\"8.5 CGPA\",\"college\":\"SVCE\"}'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2.choices[0].message.function_call.arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8b4225cc-b6a1-40fe-9548-83356fb912e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Varsha', 'grade': '8.5 CGPA', 'college': 'SVCE'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(response2.choices[0].message.function_call.arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "73c620fe-5e32-456c-a877-303b9cfbae15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use of function calling\n",
    "sd1=\"Varsha is an AI/ML enthusiast, learning happily. She loves building solutions to real-world problems. She is studying at SVCE and has secured an 8.5 CGPA.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fa3b54b6-9e70-4eaf-892b-0bc9a1d39f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd2=\"trevor is coding enthusiast. he loves building solutions to real-world problems. She is studying at nmit and has secured an 7.5 CGPA.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "576c6239-2c12-4c25-900f-9349d5de6a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Varsha', 'grade': '8.5 CGPA', 'college': 'SVCE'}\n",
      "{'name': 'trevor', 'grade': '7.5', 'college': 'nmit'}\n"
     ]
    }
   ],
   "source": [
    "student_info=[sd1,sd2]\n",
    "for student in student_info:\n",
    "    response= client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": student}],\n",
    "        functions=student_function,\n",
    "        function_call='auto'\n",
    ")\n",
    "    response=json.loads(response.choices[0].message.function_call.arguments)\n",
    "    print(response)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b115f7c2-01aa-4471-af5c-ac4d8f1d762c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling multiple functions is also possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c0425800-e049-4f5a-bf0f-6e427d632887",
   "metadata": {},
   "outputs": [],
   "source": [
    "#advanced function calling example\n",
    "function_destination= [{\n",
    "    \"name\": \"get_flight_info\",\n",
    "    \"description\": \"get the flight infomation between two locations.\",\n",
    "    \"parameters\": {\n",
    "        \"type\":\"object\",\n",
    "        \"properties\":{\n",
    "            \"loc_origin\":{\n",
    "                \"type\":\"string\",\n",
    "                \"description\":\"departure airport ,eg: delhi\" },\n",
    "            \"loc_dest\":{\n",
    "                 \"type\":\"string\",\n",
    "                \"description\":\"destination airport ,eg: mumbai\"},\n",
    "    },\n",
    "     \"required\": [\"loc_origin\", \"loc_dest\"]\n",
    "            }}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "201f83a8-d3a2-4059-b74c-fcdb0808482a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt=\"when is the next flight from delhi to mumbai?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1206f01f-c7bb-461c-9220-e696bf1246f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response2= client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": user_prompt}],\n",
    "    functions=function_destination,\n",
    "    function_call=\"auto\"\n",
    ")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0ce041fa-9bfd-47ca-853b-f2840b3a54a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"loc_origin\":\"delhi\",\"loc_dest\":\"mumbai\"}'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2.choices[0].message.function_call.arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6621123a-8773-45c1-878d-fd137a145cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling third party api to fetch data\n",
    "#this is function acts as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c2d8e61d-2c80-4fe1-857e-6d107b04bac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime,timedelta\n",
    "def get_flight_info(loc_origin,loc_dest):\n",
    "    flight_info={\n",
    "        \"loc_origin\":loc_origin,\n",
    "        \"loc_dest\":loc_dest,\n",
    "        \"datetime\":str(datetime.now()+timedelta(hours=2)),\n",
    "        \"airline\":\"KLM\",\n",
    "        \"flight\":\"KL643\",\n",
    "     }\n",
    "    return json.dumps(flight_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a9e1d201-c7b1-437d-b21a-a9ee98e9a394",
   "metadata": {},
   "outputs": [],
   "source": [
    "params=response2.choices[0].message.function_call.arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f5621a36-8478-46d2-9039-da48db7e3f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting info seperately\n",
    "origin=json.loads(params).get('loc_origin')\n",
    "destination=json.loads(params).get('loc_dest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "667431cc-c9e4-43a6-81e9-b54ba367bc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "params1=json.loads(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a37e2bd2-9e83-471e-bd1f-3ef85ffce85d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loc_origin': 'delhi', 'loc_dest': 'mumbai'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "299d7455-1e14-4ac5-9d18-4baa9b24dbaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get_flight_info'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2.choices[0].message.function_call.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8764b517-6066-44b8-88ba-46eb9281fb45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response2.choices[0].message.function_call.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2a809ef0-f43f-4153-93b1-6f309e8d1a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_func=eval(response2.choices[0].message.function_call.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "02b3a426-046d-4973-b0d8-58b5ec062dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"loc_origin\": \"delhi\", \"loc_dest\": \"mumbai\", \"datetime\": \"2025-07-30 11:30:17.106168\", \"airline\": \"KLM\", \"flight\": \"KL643\"}\n"
     ]
    }
   ],
   "source": [
    "flight=chosen_func(**params1)\n",
    "print(flight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5df896b0-84ed-497a-b20a-86419ba990bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "response3= client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": user_prompt},\n",
    "              {\"role\":\"function\",\"name\":response2.choices[0].message.function_call.name,\"content\":flight}],\n",
    "    functions=function_destination, #add function calling\n",
    "    function_call=\"auto\"\n",
    ")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "463438c1-016a-4326-854e-4901f5b9b624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-BysHFe1iK0bb5oohNVug51vONIUls', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The next flight from Delhi to Mumbai is on July 30, 2025 at 11:30 AM. The airline is KLM and the flight number is KL643.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1753848021, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=37, prompt_tokens=143, total_tokens=180, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "529da670-a5a8-427b-8eb5-682028f0d68b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The next flight from Delhi to Mumbai is on July 30, 2025 at 11:30 AM. The airline is KLM and the flight number is KL643.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response3.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786cdb70-4418-4953-9c29-3b84fb0518c9",
   "metadata": {},
   "source": [
    "LangChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "050c4801-4bff-4868-9715-8536381e4245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5aa3df93-d39c-4987-b41a-390300ab73d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a6628cdf-2aa8-479e-9541-efda3f125889",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varsh\\AppData\\Local\\Temp\\ipykernel_11612\\3284633972.py:1: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  client= OpenAI(openai_api_key=mykey)\n"
     ]
    }
   ],
   "source": [
    "client= OpenAI(openai_api_key=mykey)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ff0f600a-2bcb-479f-bcd5-80150ccab8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"tell me a funny slang used by genz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a1677d29-c72b-45a3-9834-078ad8679f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Flexing on the \\'gram\" - boasting or showing off on social media.'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.invoke(prompt).strip()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "00bcc39f-457b-49a6-861e-0c34a1facf22",
   "metadata": {},
   "source": [
    "Prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "96dba910-6958-4212-894a-72229df13bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e020b3d3-6059-4463-bb81-a37d21617f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_name=PromptTemplate(\n",
    "    input_variable=[\"city\"],\n",
    "    template=\"can you tell me the captial of {city}?\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9a3fbc86-5bf4-4fab-94a6-1f22ad8359e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1=prompt_template_name.format(city=\"Karnataka\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "db0f6e88-b053-472d-8019-87248b299e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of Karnataka is Bengaluru.'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.predict(p1).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "99b091ed-cce0-4ea5-a3f6-a46a5cf08445",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Langchain gives two ways to create prompttemplate\n",
    "prompt=PromptTemplate.from_template(\"give me the unique company name that manufactures {product}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9407b04a-d051-4922-856b-1c3e4dbae0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'give me the unique company name that manufactures vintage car'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.format(product=\"vintage car\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ec417695-6ad3-4d03-86e6-85b9cb84f4a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Retro Rides Co.\"'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.predict(prompt).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de1286c-017d-41ac-9046-a4d7f8d2dc1c",
   "metadata": {},
   "source": [
    "AGENT IN LANGCHAIN :helps to get any tools from third party api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027bd510-b86e-4ba8-a8ae-624b276660ff",
   "metadata": {},
   "source": [
    "***using serp api (we can call google_search_engine)to extract real time info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fbbda2ba-3c10-4427-a44a-f0a8ba61ef9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-search-results in c:\\users\\varsh\\anaconda3\\envs\\testingopenai\\lib\\site-packages (2.4.2)\n",
      "Requirement already satisfied: requests in c:\\users\\varsh\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from google-search-results) (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\varsh\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from requests->google-search-results) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\varsh\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from requests->google-search-results) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\varsh\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from requests->google-search-results) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\varsh\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from requests->google-search-results) (2025.7.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb1e14c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc4b9e4-b562-4326-8383-afebb93fd0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "serpapi_key=\"your_api_key_of_serp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3d0b75ec-10e4-4193-8813-2c71539d44ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.llms import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e9214fb1-1e7b-4c77-bc4a-2c40c6a4ea63",
   "metadata": {},
   "outputs": [],
   "source": [
    "client= OpenAI(openai_api_key=mykey)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "654bbdf1-98f7-4f09-acc0-16660da05485",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool=load_tools([\"serpapi\"],serpapi_api_key=serpapi_key,llm=client)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "385ca21e-ded6-4bd5-b0aa-79e04d5cc766",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent=initialize_agent(tool,client,agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,verbose=True)   #verbose gives every info of whatever happening in backenda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b5b79914-2669-4c4e-b3c7-4475370e45bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m It would be helpful to use a search engine to find a reliable source for current affairs.\n",
      "Action: Search\n",
      "Action Input: \"top 5 current affairs\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m['Current Affairs Today – Current Affairs – 2025-26 · State of Food and Nutrition in the World · Sundarbans Tiger Reserve Expansion · Daily Current Affairs Quiz: ...', \"Stay updated with the latest current affairs for 2025. Get today's top news, political developments, global events, and trending topics to keep you informed ...\", \"Trump administration asks judges to release Epstein, Maxwell grand jury transcripts · NYC skyscraper shooter's 'suicide note' blamed NFL for brain disease.\", 'Latest world news headlines: International breaking news and current affairs from US, Europe, Middle East, Asia, Africa and more. If it happens around the ...', 'Top Current Affairs contains latest weekly current affairs and news from all over the world ... Top 5 Current Affairs of the Day: 14 November 2022- Doodle for ...', 'Current affairs questions and answers with explanations are provided for your competitive exams, placement interviews, and entrance tests.', \"North Korea's sacred Mount Paektu designated as UNESCO Global Geopark · American food: 20 of the greatest dishes · French resort town cracks down on 'half-naked' ...\", \"Sirens blare in Hawaii and millions are evacuated in Japan after one of the strongest earthquakes ever recorded hits Russia's eastern coast.\", 'Current Affairs Question | Top 10 One Liner (Daily 5 Min) | By Vivek Sir. Examपुर · 10:47 · Current Affairs Question | Top 10 One Liner (Daily 5 Min) | By ...']\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "agent.run(\"can you tell me top 5 current affairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb382747-6dd6-4b85-959e-8d333ee56613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from wikipedia\n",
    "!pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232a6854-bc87-4d35-b8d1-cb600384b086",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool=load_tools([\"wikipedia\"],llm=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87f3af4-db62-419f-bf55-df3ba028ea44",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent=initialize_agent(tool,client,agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13f2ba4-ea07-48de-80b7-49758c6b5869",
   "metadata": {},
   "source": [
    "agent.run(\"ask your question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d32b1f-45b3-4c33-b057-d8a6acbf1118",
   "metadata": {},
   "outputs": [],
   "source": [
    "#langchain documentation is the best tool to learn langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42c4908-9847-4205-8f8b-adde1c1d1c90",
   "metadata": {},
   "source": [
    "CHAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "3fbc2e79-d199-454e-b325-da2f75b089b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAI(client=<openai.resources.completions.Completions object at 0x000002934E1C1480>, async_client=<openai.resources.completions.AsyncCompletions object at 0x000002934E1E0370>, model_kwargs={}, openai_api_key='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', openai_proxy='', logit_bias={})"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0c9d4663-85f3-41b9-b238-861fc0626eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "prompt=PromptTemplate.from_template(\"give me the unique company name that manufactures {product}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "785c81fb-355f-4d26-81b7-ebe1cc65ae60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "048e5565-548f-4e3e-b2c0-5016d58638a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=LLMChain(llm=client,prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "97021f8d-0910-485d-b47a-a6035e0f2801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VinoCraft Co.'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"wine\").strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f170ea11-2cf3-48b7-a683-a3cc3f575fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ex 2 for chain\n",
    "prompt_template_name=PromptTemplate(\n",
    "    input_variable=[\"cuisine\"],\n",
    "    template=\"i want to open a resturant ,do you want to recommend a fancy name for {cuisine}?\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "1176fdec-e64b-408e-bbeb-78c11d2ba1f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['cuisine'], input_types={}, partial_variables={}, template='i want to open a resturant ,do you want to recommend a fancy name for {cuisine}?')"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "5f705b40-6918-4cbc-9e52-74074f9d59a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=LLMChain(llm=client,prompt=prompt_template_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "7fdfcb56-6221-4f7f-9494-15ca1823c810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here are a few suggestions:\\n\\n1. \"Spice Haven\"\\n2. \"Curry Palace\"\\n3. \"Tandoori Delight\"\\n4. \"Naan & Beyond\"\\n5. \"Saffron Dreams\"\\n6. \"Raj Mahal\"\\n7. \"Masala Mania\"\\n8. \"Chai Chateau\"\\n9. \"Garam Masala Grill\"\\n10. \"Bollywood Bites\"'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"Indian\").strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a7b508-17fb-4444-8a24-dbe1ac59ee35",
   "metadata": {},
   "source": [
    "if we want to combine multiple chain & set a sequence we use simple sequential chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "bb399ebf-c841-46f7-a71c-47877f06d6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex for simple sequential chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "970ac84f-b67b-43fe-91a9-6b2bb0230add",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_name=PromptTemplate(\n",
    "    input_variable=[\"startup_name\"],\n",
    "    template=\"can you suggest name for {startup_name}startup?\"\n",
    "    )\n",
    "name_chain=LLMChain(llm=client,prompt=prompt_template_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "f392657a-f4f1-4aef-9938-a607869ede88",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_item=PromptTemplate(\n",
    "    input_variable=[\"name\"],\n",
    "    template=\"can you suggest some strategies for {name}\"\n",
    "    )\n",
    "strategy_chain=LLMChain(llm=client,prompt=prompt_template_item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "e8787efc-d792-4544-b151-c0a82cab2efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "7b15b840-110c-478c-847b-40f435e1a6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain= SimpleSequentialChain(chains=[name_chain,strategy_chain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "66b96f35-9952-4b57-bfef-839ae26889e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. AIgenius:\n",
      "- Establish a strong online presence through social media and a professional website to showcase AIgenius' capabilities and expertise.\n",
      "- Partner with other AI companies or organizations to expand reach and collaborate on projects.\n",
      "- Attend industry events and conferences to network and showcase AIgenius' services.\n",
      "- Offer free demos or trials to potential clients to showcase the power and effectiveness of AIgenius.\n",
      "- Utilize targeted advertising to reach potential clients in relevant industries.\n",
      "- Develop case studies or success stories to demonstrate the impact of AIgenius on businesses.\n",
      "- Offer personalized and tailored solutions to suit the unique needs of each client.\n",
      "- Continuously stay updated on the latest developments and advancements in AI technology to stay ahead of the competition.\n",
      "\n",
      "2. MindMatrix:\n",
      "- Develop a strong brand identity and messaging to differentiate MindMatrix from competitors.\n",
      "- Utilize content marketing to establish MindMatrix as a thought leader in the AI industry.\n",
      "- Offer educational resources such as webinars, white papers, and blog posts to showcase the benefits and applications of MindMatrix's AI solutions.\n",
      "- Collaborate with universities or research institutions to showcase the scientific and academic backing of MindMatrix's technology.\n",
      "- Offer personalized demos or trials to potential clients to showcase the effectiveness of MindMatrix's solutions.\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"artificial intelligence\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd49a870-7c85-43b4-ae76-c3313e96d34d",
   "metadata": {},
   "source": [
    "document loaders: reading any sort of doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "6ca0aa85-1a9d-447f-9451-e9d444d4c5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Downloading pypdf-5.9.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in c:\\users\\varsh\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from pypdf) (4.14.1)\n",
      "Downloading pypdf-5.9.0-py3-none-any.whl (313 kB)\n",
      "Installing collected packages: pypdf\n",
      "Successfully installed pypdf-5.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "3932e5b2-f2b8-4784-bf30-c4d7c27b3685",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(r\"C:\\Users\\varsh\\Downloads\\Java_OOP_Model_Answers.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "12f0a97c-b577-434a-b0b2-6dd09002058e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "d7297318-4d5b-4201-be2f-fc8c54affb4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'PyFPDF 1.7.2 http://pyfpdf.googlecode.com/', 'creator': 'PyPDF', 'creationdate': 'D:20250713080148', 'source': 'C:\\\\Users\\\\varsh\\\\Downloads\\\\Java_OOP_Model_Answers.pdf', 'total_pages': 3, 'page': 0, 'page_label': '1'}, page_content='Object Oriented Programming with JAVA - Model Question Paper Answers\\nModule 1\\nQ1 a) Explain different lexical issues in JAVA.\\n(Answer provided earlier with example code)\\nQ1 b) Define Array. Write a Java program to implement the addition of two matrices.\\n(Answer provided earlier with example code)\\nQ1 c) Explain the following operations with examples: <<, >>, >>>\\n(Answer provided earlier with example code)\\nQ2 a) Explain object-oriented principles.\\n(Answer provided earlier with example code)\\nQ2 b) Write a Java program to sort the elements using a for loop.\\n(Answer provided earlier with example code)\\nQ2 c) Explain different types of if statements in JAVA.\\n(Answer provided earlier with example code)\\nModule 2\\nQ3 a) What are constructors? Explain two types of constructors with an example.\\n(Answer provided earlier with example code)\\nQ3 b) Define recursion. Write a recursive program to find nth Fibonacci number.\\n(Answer provided earlier with example code)\\nQ3 c) Explain the various access specifiers in Java.\\n(Answer provided earlier with example code)\\nQ4 a) Explain call by value and call by reference with an example program.\\n(Answer provided earlier with example code)\\nQ4 b) Write a program to perform Stack operations using proper class and methods.\\n(Answer provided earlier with example code)\\nQ4 c) Explain the use of this in JAVA with an example.\\n(Answer provided earlier with example code)\\nModule 3\\nQ5 a) Write a Java program to implement multilevel inheritance with 3 levels of hierarchy.'),\n",
       " Document(metadata={'producer': 'PyFPDF 1.7.2 http://pyfpdf.googlecode.com/', 'creator': 'PyPDF', 'creationdate': 'D:20250713080148', 'source': 'C:\\\\Users\\\\varsh\\\\Downloads\\\\Java_OOP_Model_Answers.pdf', 'total_pages': 3, 'page': 1, 'page_label': '2'}, page_content='Object Oriented Programming with JAVA - Model Question Paper Answers\\n(Answer provided earlier with example code)\\nQ5 b) Explain how an interface is used to achieve multiple inheritance in Java.\\n(Answer provided earlier with example code)\\nQ5 c) Explain method overriding with a suitable example.\\n(Answer provided earlier with example code)\\nQ6 a) What is single-level inheritance? Write a Java program to implement it.\\n(Answer provided earlier with example code)\\nQ6 b) What is the importance of the super keyword in inheritance?\\n(Answer provided earlier with example code)\\nQ6 c) What is abstract class and abstract method? Explain with an example.\\n(Answer provided earlier with example code)\\nModule 4\\nQ7 a) Define package. Explain steps to create user-defined package with example.\\n(Answer provided earlier with example code)\\nQ7 b) Write a program that throws IllegalAccessException and handles it properly.\\n(Answer provided earlier with example code)\\nQ7 c) Define exception. Explain key terms used in exception handling.\\n(Answer provided earlier with example code)\\nQ8 a) Explain importing packages in Java with an example.\\n(Answer provided earlier with example code)\\nQ8 b) How to create your own exception class? Explain with a program.\\n(Answer provided earlier with example code)\\nQ8 c) Demonstrate working of nested try block with an example.\\n(Answer provided earlier with example code)\\nModule 5\\nQ9 a) What is a thread? Explain different ways of creating threads.\\n(Answer provided earlier with example code)\\nQ9 b) What is the need for synchronization? Explain with an example.\\n(Answer provided earlier with example code)'),\n",
       " Document(metadata={'producer': 'PyFPDF 1.7.2 http://pyfpdf.googlecode.com/', 'creator': 'PyPDF', 'creationdate': 'D:20250713080148', 'source': 'C:\\\\Users\\\\varsh\\\\Downloads\\\\Java_OOP_Model_Answers.pdf', 'total_pages': 3, 'page': 2, 'page_label': '3'}, page_content='Object Oriented Programming with JAVA - Model Question Paper Answers\\nQ9 c) Discuss values() and valueOf() methods in Enumerations with examples.\\n(Answer provided earlier with example code)\\nQ10 a) What is multithreading? Write a program to create multiple threads.\\n(Answer provided earlier with example code)\\nQ10 b) Explain inter-thread communication with an example.\\n(Answer provided earlier with example code)\\nQ10 c) Explain auto-boxing/unboxing in expressions.\\n(Answer provided earlier with example code)')]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9769991d-faa3-4318-a33c-8f11cd019cfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
